#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è®­ç»ƒå¹³è¡¡çš„äºŒåˆ†ç±»æ¨¡å‹
- é™ä½é˜ˆå€¼è‡³0.8%
- åˆ é™¤éœ‡è¡æ ·æœ¬
- å¹³è¡¡ä¸Šæ¶¨å’Œä¸‹è·Œæ ·æœ¬
"""

import sys
import os
import argparse
from datetime import datetime, timezone, timedelta
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score
import joblib

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from config.settings import SYMBOL, TIMEFRAME, BASE_PATH
from data.fetcher import fetch_ohlcv
from data.features import add_features

# å¹³è¡¡çš„ç›®æ ‡å®šä¹‰
PREDICTION_WINDOW = 4  # é¢„æµ‹æœªæ¥4æ ¹Kçº¿
UP_THRESHOLD = 0.008  # ä¸Šæ¶¨é˜ˆå€¼ï¼š0.8%
DOWN_THRESHOLD = -0.008  # ä¸‹è·Œé˜ˆå€¼ï¼š-0.8%

def prepare_balanced_data(df, prediction_window=PREDICTION_WINDOW):
    """
    å‡†å¤‡å¹³è¡¡çš„è®­ç»ƒæ•°æ®
    
    ç›®æ ‡å®šä¹‰ï¼š
    - 1 (ä¸Šæ¶¨): æœªæ¥æ”¶ç›Šç‡ > 0.8%
    - 0 (ä¸‹è·Œ): æœªæ¥æ”¶ç›Šç‡ < -0.8%
    - åˆ é™¤: -0.8% <= æœªæ¥æ”¶ç›Šç‡ <= 0.8% (éœ‡è¡)
    """
    print(f"ğŸ“Š å‡†å¤‡å¹³è¡¡æ•°æ®...")
    print(f"  é¢„æµ‹çª—å£: {prediction_window}æ ¹Kçº¿")
    print(f"  ä¸Šæ¶¨é˜ˆå€¼: >{UP_THRESHOLD*100:.1f}%")
    print(f"  ä¸‹è·Œé˜ˆå€¼: <{DOWN_THRESHOLD*100:.1f}%")
    
    # è®¡ç®—æœªæ¥æ”¶ç›Šç‡
    df['future_return'] = (df['close'].shift(-prediction_window) - df['close']) / df['close']
    
    # åˆ é™¤æ— æ³•è®¡ç®—çš„è¡Œ
    df = df.dropna(subset=['future_return'])
    
    total_before = len(df)
    
    # å®šä¹‰ç›®æ ‡å¹¶åˆ é™¤éœ‡è¡æ ·æœ¬
    def classify(ret):
        if ret > UP_THRESHOLD:
            return 1  # ä¸Šæ¶¨
        elif ret < DOWN_THRESHOLD:
            return 0  # ä¸‹è·Œ
        else:
            return None  # éœ‡è¡ï¼Œå°†è¢«åˆ é™¤
    
    df['target'] = df['future_return'].apply(classify)
    
    # åˆ é™¤éœ‡è¡æ ·æœ¬
    df = df.dropna(subset=['target'])
    df['target'] = df['target'].astype(int)
    
    total_after = len(df)
    removed = total_before - total_after
    
    print(f"\n  æ ·æœ¬å¤„ç†:")
    print(f"    åŸå§‹æ ·æœ¬: {total_before}")
    print(f"    åˆ é™¤éœ‡è¡: {removed} ({removed/total_before*100:.1f}%)")
    print(f"    ä¿ç•™æ ·æœ¬: {total_after} ({total_after/total_before*100:.1f}%)")
    
    # ç»Ÿè®¡ä¿¡æ¯
    class_counts = df['target'].value_counts().sort_index()
    
    print(f"\n  æ ·æœ¬åˆ†å¸ƒ:")
    print(f"    ä¸‹è·Œ (0): {class_counts.get(0, 0)} ({class_counts.get(0, 0)/len(df)*100:.1f}%)")
    print(f"    ä¸Šæ¶¨ (1): {class_counts.get(1, 0)} ({class_counts.get(1, 0)/len(df)*100:.1f}%)")
    
    # è®¡ç®—å¹³è¡¡åº¦
    if len(class_counts) == 2:
        balance_ratio = min(class_counts) / max(class_counts)
        print(f"    å¹³è¡¡åº¦: {balance_ratio:.2f} (1.0ä¸ºå®Œå…¨å¹³è¡¡)")
    
    # æ”¶ç›Šç‡ç»Ÿè®¡
    print(f"\n  æ”¶ç›Šç‡ç»Ÿè®¡:")
    for cls, label in [(0, 'ä¸‹è·Œ'), (1, 'ä¸Šæ¶¨')]:
        if cls in class_counts.index:
            cls_returns = df[df['target'] == cls]['future_return']
            print(f"    {label}: å‡å€¼{cls_returns.mean()*100:.3f}%, "
                  f"æ ‡å‡†å·®{cls_returns.std()*100:.3f}%, "
                  f"èŒƒå›´[{cls_returns.min()*100:.2f}%, {cls_returns.max()*100:.2f}%]")
    
    return df

def train_balanced_model(limit=35000, since_days=365):
    """è®­ç»ƒå¹³è¡¡çš„äºŒåˆ†ç±»æ¨¡å‹"""
    
    print("=" * 80)
    print("è®­ç»ƒå¹³è¡¡çš„äºŒåˆ†ç±»æ¨¡å‹")
    print("=" * 80)
    print(f"\né…ç½®:")
    print(f"  äº¤æ˜“å¯¹: {SYMBOL}")
    print(f"  å‘¨æœŸ: {TIMEFRAME}")
    print(f"  æ•°æ®é‡: {limit}æ¡")
    print(f"  æ—¶é—´èŒƒå›´: æœ€è¿‘{since_days}å¤©")
    
    # è·å–æ•°æ®
    print(f"\nâ³ è·å–å†å²æ•°æ®...")
    since_date = datetime.now(timezone.utc) - timedelta(days=since_days)
    df = fetch_ohlcv(SYMBOL, TIMEFRAME, limit=limit, since=since_date)
    
    if df is None or df.empty:
        print("âŒ æ•°æ®è·å–å¤±è´¥")
        return None
    
    print(f"âœ… è·å– {len(df)} æ ¹Kçº¿")
    
    # æ·»åŠ ç‰¹å¾
    print(f"\nğŸ§© æ„å»ºç‰¹å¾...")
    df = add_features(df)
    
    if df.empty:
        print("âŒ ç‰¹å¾æ„å»ºå¤±è´¥")
        return None
    
    # å‡†å¤‡å¹³è¡¡æ•°æ®
    df = prepare_balanced_data(df, PREDICTION_WINDOW)
    
    # ç‰¹å¾åˆ—
    feature_cols = [
        'open', 'high', 'low', 'close', 'volume',
        'return', 'log_return',
        'ma20', 'ma50', 'ma_diff',
        'rsi', 'macd', 'macd_signal', 'macd_hist',
        'volatility', 'volume_ratio'
    ]
    
    # æ£€æŸ¥ç‰¹å¾
    missing_cols = [col for col in feature_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ ç¼ºå°‘ç‰¹å¾: {missing_cols}")
        return None
    
    # åˆ é™¤åŒ…å«NaNçš„è¡Œ
    df = df.dropna(subset=feature_cols + ['target'])
    
    print(f"\nğŸ§© ç‰¹å¾ç»´åº¦: {len(feature_cols)} | æœ‰æ•ˆæ ·æœ¬: {len(df)}")
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X = df[feature_cols].values
    y = df['target'].values
    
    # åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, shuffle=False
    )
    
    print(f"ğŸ“Š è®­ç»ƒé›†: {len(X_train)} | æµ‹è¯•é›†: {len(X_test)}")
    
    # ç»Ÿè®¡è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„åˆ†å¸ƒ
    train_dist = pd.Series(y_train).value_counts().sort_index()
    test_dist = pd.Series(y_test).value_counts().sort_index()
    
    print(f"\nè®­ç»ƒé›†åˆ†å¸ƒ:")
    print(f"  ä¸‹è·Œ: {train_dist.get(0, 0)} ({train_dist.get(0, 0)/len(y_train)*100:.1f}%)")
    print(f"  ä¸Šæ¶¨: {train_dist.get(1, 0)} ({train_dist.get(1, 0)/len(y_train)*100:.1f}%)")
    
    print(f"\næµ‹è¯•é›†åˆ†å¸ƒ:")
    print(f"  ä¸‹è·Œ: {test_dist.get(0, 0)} ({test_dist.get(0, 0)/len(y_test)*100:.1f}%)")
    print(f"  ä¸Šæ¶¨: {test_dist.get(1, 0)} ({test_dist.get(1, 0)/len(y_test)*100:.1f}%)")
    
    # è®­ç»ƒLightGBMäºŒåˆ†ç±»æ¨¡å‹
    print(f"\nğŸš€ è®­ç»ƒLightGBMå¹³è¡¡æ¨¡å‹...")
    
    params = {
        'objective': 'binary',
        'metric': 'auc',
        'boosting_type': 'gbdt',
        'num_leaves': 31,
        'learning_rate': 0.05,
        'feature_fraction': 0.9,
        'bagging_fraction': 0.8,
        'bagging_freq': 5,
        'verbose': -1,
        'seed': 42,
        'is_unbalance': True  # å¤„ç†å¯èƒ½çš„è½»å¾®ä¸å¹³è¡¡
    }
    
    train_data = lgb.Dataset(X_train, label=y_train)
    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)
    
    model = lgb.train(
        params,
        train_data,
        num_boost_round=500,
        valid_sets=[test_data],
        callbacks=[
            lgb.early_stopping(stopping_rounds=50),
            lgb.log_evaluation(period=100)
        ]
    )
    
    # è¯„ä¼°æ¨¡å‹
    print(f"\nğŸ“ˆ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)
    
    # AUC
    train_auc = roc_auc_score(y_train, y_pred_train)
    test_auc = roc_auc_score(y_test, y_pred_test)
    
    print(f"\nAUC:")
    print(f"  è®­ç»ƒé›†: {train_auc:.4f}")
    print(f"  æµ‹è¯•é›†: {test_auc:.4f}")
    
    # å‡†ç¡®ç‡ï¼ˆä½¿ç”¨0.5é˜ˆå€¼ï¼‰
    train_acc = accuracy_score(y_train, (y_pred_train > 0.5).astype(int))
    test_acc = accuracy_score(y_test, (y_pred_test > 0.5).astype(int))
    
    print(f"\nå‡†ç¡®ç‡ (é˜ˆå€¼0.5):")
    print(f"  è®­ç»ƒé›†: {train_acc*100:.2f}%")
    print(f"  æµ‹è¯•é›†: {test_acc*100:.2f}%")
    
    # é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
    print(f"\né¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ (æµ‹è¯•é›†):")
    print(f"  æœ€å°å€¼: {y_pred_test.min():.4f}")
    print(f"  æœ€å¤§å€¼: {y_pred_test.max():.4f}")
    print(f"  å‡å€¼: {y_pred_test.mean():.4f}")
    print(f"  ä¸­ä½æ•°: {np.median(y_pred_test):.4f}")
    print(f"  æ ‡å‡†å·®: {y_pred_test.std():.4f}")
    
    # åˆ†ä½æ•°
    print(f"\nåˆ†ä½æ•°:")
    for p in [5, 25, 50, 75, 95]:
        print(f"  {p:2d}%: {np.percentile(y_pred_test, p):.4f}")
    
    # é¢„æµ‹åˆ†å¸ƒ
    print(f"\né¢„æµ‹åˆ†å¸ƒ (é˜ˆå€¼0.5):")
    pred_down = (y_pred_test < 0.5).sum()
    pred_up = (y_pred_test >= 0.5).sum()
    print(f"  é¢„æµ‹ä¸‹è·Œ (<0.5): {pred_down} ({pred_down/len(y_pred_test)*100:.1f}%)")
    print(f"  é¢„æµ‹ä¸Šæ¶¨ (>=0.5): {pred_up} ({pred_up/len(y_pred_test)*100:.1f}%)")
    
    # æ··æ·†çŸ©é˜µ
    print(f"\næ··æ·†çŸ©é˜µ (æµ‹è¯•é›†, é˜ˆå€¼0.5):")
    y_pred_binary = (y_pred_test > 0.5).astype(int)
    cm = confusion_matrix(y_test, y_pred_binary)
    print("           é¢„æµ‹ä¸‹è·Œ  é¢„æµ‹ä¸Šæ¶¨")
    print(f"å®é™…ä¸‹è·Œ    {cm[0][0]:6d}    {cm[0][1]:6d}")
    print(f"å®é™…ä¸Šæ¶¨    {cm[1][0]:6d}    {cm[1][1]:6d}")
    
    # åˆ†ç±»æŠ¥å‘Š
    print(f"\nåˆ†ç±»æŠ¥å‘Š (æµ‹è¯•é›†):")
    target_names = ['ä¸‹è·Œ', 'ä¸Šæ¶¨']
    print(classification_report(y_test, y_pred_binary, target_names=target_names, zero_division=0))
    
    # ç‰¹å¾é‡è¦æ€§
    print(f"\nğŸ“Š ç‰¹å¾é‡è¦æ€§ (Top 10):")
    importance = model.feature_importance(importance_type='gain')
    feature_importance = sorted(
        zip(feature_cols, importance),
        key=lambda x: x[1],
        reverse=True
    )
    for i, (feat, imp) in enumerate(feature_importance[:10], 1):
        print(f"  {i}. {feat}: {imp:.0f}")
    
    # ä¿å­˜æ¨¡å‹
    model_dir = BASE_PATH / 'models' / 'registry'
    model_dir.mkdir(parents=True, exist_ok=True)
    
    version = datetime.now().strftime('v%Y%m%d_%H%M')
    model_path = model_dir / f'{version}_balanced.pkl'
    metadata_path = model_dir / f'{version}_balanced.json'
    
    joblib.dump(model, model_path)
    
    metadata = {
        'version': version,
        'type': 'balanced_binary',
        'symbol': SYMBOL,
        'timeframe': TIMEFRAME,
        'prediction_window': PREDICTION_WINDOW,
        'up_threshold': UP_THRESHOLD,
        'down_threshold': DOWN_THRESHOLD,
        'train_samples': len(X_train),
        'test_samples': len(X_test),
        'test_auc': float(test_auc),
        'test_accuracy': float(test_acc),
        'pred_prob_min': float(y_pred_test.min()),
        'pred_prob_max': float(y_pred_test.max()),
        'pred_prob_mean': float(y_pred_test.mean()),
        'pred_prob_std': float(y_pred_test.std()),
        'features': feature_cols,
        'created_at': datetime.now(timezone.utc).isoformat()
    }
    
    import json
    with open(metadata_path, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    # æ›´æ–°latestæŒ‡é’ˆ
    latest_path = model_dir / 'latest_balanced.txt'
    with open(latest_path, 'w') as f:
        f.write(version)
    
    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜:")
    print(f"  ç‰ˆæœ¬: {version}")
    print(f"  è·¯å¾„: {model_path}")
    print(f"  å…ƒæ•°æ®: {metadata_path}")
    
    print(f"\nâœ… è®­ç»ƒæˆåŠŸ!")
    print(f"  æµ‹è¯•é›†AUC: {test_auc:.4f}")
    print(f"  é¢„æµ‹æ¦‚ç‡èŒƒå›´: [{y_pred_test.min():.4f}, {y_pred_test.max():.4f}]")
    
    # éªŒè¯åŒå‘é¢„æµ‹èƒ½åŠ›
    if y_pred_test.max() > 0.5 and y_pred_test.min() < 0.5:
        print(f"\nâœ… æ¨¡å‹å…·å¤‡åŒå‘é¢„æµ‹èƒ½åŠ›ï¼")
        print(f"  å¯ä»¥é¢„æµ‹ä¸Šæ¶¨ (æ¦‚ç‡>0.5)")
        print(f"  å¯ä»¥é¢„æµ‹ä¸‹è·Œ (æ¦‚ç‡<0.5)")
    else:
        print(f"\nâš ï¸  æ¨¡å‹å¯èƒ½ä»ç„¶åå‘å•ä¾§")
        if y_pred_test.max() <= 0.5:
            print(f"  æ‰€æœ‰é¢„æµ‹éƒ½<0.5ï¼Œä»ç„¶åªé¢„æµ‹ä¸‹è·Œ")
        if y_pred_test.min() >= 0.5:
            print(f"  æ‰€æœ‰é¢„æµ‹éƒ½>0.5ï¼Œåªé¢„æµ‹ä¸Šæ¶¨")
    
    return model_path

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è®­ç»ƒå¹³è¡¡çš„äºŒåˆ†ç±»æ¨¡å‹')
    parser.add_argument('--limit', type=int, default=35000, help='æ•°æ®é‡')
    parser.add_argument('--since_days', type=int, default=365, help='æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰')
    
    args = parser.parse_args()
    
    model_path = train_balanced_model(
        limit=args.limit,
        since_days=args.since_days
    )
    
    sys.exit(0 if model_path else 1)
