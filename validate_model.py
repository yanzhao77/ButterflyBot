#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯è®­ç»ƒå¥½çš„æ¨¡å‹æ€§èƒ½
"""

import sys
import os
import pandas as pd
import numpy as np
from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config.settings import BASE_PATH, SYMBOL, TIMEFRAME
from data.features import add_features, get_feature_columns
from model.model_registry import load_model_by_version, load_latest_model_path
import joblib

print("=" * 80)
print("æ¨¡å‹æ€§èƒ½éªŒè¯")
print("=" * 80)

def load_test_data():
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    cache_dir = BASE_PATH / 'cached_data'
    filename = f"binance_{SYMBOL.replace('/', '_')}_{TIMEFRAME}.csv"
    cache_path = cache_dir / filename
    
    if not cache_path.exists():
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {cache_path}")
        return None
    
    print(f"\nğŸ“‚ åŠ è½½æ•°æ®: {cache_path}")
    
    df = pd.read_csv(cache_path)
    df['timestamp'] = pd.to_datetime(df['timestamp'], utc=True)
    df.set_index('timestamp', inplace=True)
    
    print(f"âœ… åŠ è½½æˆåŠŸ: {len(df)} æ¡æ•°æ®")
    
    # æ·»åŠ ç‰¹å¾
    print("ğŸ§© æ„å»ºç‰¹å¾...")
    df_feat = add_features(df)
    
    print(f"âœ… ç‰¹å¾æ„å»ºå®Œæˆ: {len(df_feat)} æ¡æœ‰æ•ˆæ•°æ®")
    
    return df_feat

def validate_model(model, df_feat):
    """éªŒè¯æ¨¡å‹æ€§èƒ½"""
    
    feature_cols = get_feature_columns()
    
    # ä½¿ç”¨å30%çš„æ•°æ®ä½œä¸ºéªŒè¯é›†
    split_idx = int(len(df_feat) * 0.7)
    df_test = df_feat.iloc[split_idx:]
    
    print(f"\nğŸ“Š éªŒè¯é›†å¤§å°: {len(df_test)} æ¡")
    
    X_test = df_test[feature_cols]
    y_test = df_test['target']
    
    # é¢„æµ‹
    print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
    y_pred_proba = model.predict(X_test)
    y_pred = (y_pred_proba >= 0.5).astype(int)
    
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    print("\n" + "=" * 80)
    print("æ€§èƒ½æŒ‡æ ‡")
    print("=" * 80)
    
    # AUC
    try:
        auc = roc_auc_score(y_test, y_pred_proba)
        print(f"\nğŸ“ˆ AUC: {auc:.4f}")
        if auc >= 0.7:
            print("   âœ… ä¼˜ç§€ (â‰¥0.7)")
        elif auc >= 0.6:
            print("   âš ï¸  è‰¯å¥½ (0.6-0.7)")
        else:
            print("   âŒ è¾ƒå·® (<0.6)")
    except Exception as e:
        print(f"âš ï¸  AUCè®¡ç®—å¤±è´¥: {e}")
        auc = None
    
    # å‡†ç¡®ç‡
    accuracy = accuracy_score(y_test, y_pred)
    print(f"\nğŸ¯ å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)")
    
    # ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    
    print(f"ğŸ” ç²¾ç¡®ç‡: {precision:.4f} ({precision*100:.2f}%)")
    print(f"ğŸ” å¬å›ç‡: {recall:.4f} ({recall*100:.2f}%)")
    print(f"ğŸ” F1åˆ†æ•°: {f1:.4f}")
    
    # æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()
    
    print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ:")
    print(f"   çœŸé˜´æ€§(TN): {tn:5d}  |  å‡é˜³æ€§(FP): {fp:5d}")
    print(f"   å‡é˜´æ€§(FN): {fn:5d}  |  çœŸé˜³æ€§(TP): {tp:5d}")
    
    # é¢„æµ‹åˆ†å¸ƒ
    print(f"\nğŸ“Š é¢„æµ‹åˆ†å¸ƒ:")
    print(f"   é¢„æµ‹ä¸Šæ¶¨: {y_pred.sum()} ({y_pred.sum()/len(y_pred)*100:.1f}%)")
    print(f"   é¢„æµ‹ä¸‹è·Œ: {len(y_pred)-y_pred.sum()} ({(len(y_pred)-y_pred.sum())/len(y_pred)*100:.1f}%)")
    
    print(f"\nğŸ“Š å®é™…åˆ†å¸ƒ:")
    print(f"   å®é™…ä¸Šæ¶¨: {y_test.sum()} ({y_test.sum()/len(y_test)*100:.1f}%)")
    print(f"   å®é™…ä¸‹è·Œ: {len(y_test)-y_test.sum()} ({(len(y_test)-y_test.sum())/len(y_test)*100:.1f}%)")
    
    # æ¦‚ç‡åˆ†å¸ƒ
    print(f"\nğŸ“Š é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ:")
    print(f"   æœ€å°å€¼: {y_pred_proba.min():.4f}")
    print(f"   25åˆ†ä½: {np.percentile(y_pred_proba, 25):.4f}")
    print(f"   ä¸­ä½æ•°: {np.median(y_pred_proba):.4f}")
    print(f"   75åˆ†ä½: {np.percentile(y_pred_proba, 75):.4f}")
    print(f"   æœ€å¤§å€¼: {y_pred_proba.max():.4f}")
    print(f"   å¹³å‡å€¼: {y_pred_proba.mean():.4f}")
    print(f"   æ ‡å‡†å·®: {y_pred_proba.std():.4f}")
    
    # é«˜ç½®ä¿¡åº¦é¢„æµ‹
    high_conf_threshold = 0.7
    low_conf_threshold = 0.3
    
    high_conf_up = (y_pred_proba >= high_conf_threshold).sum()
    high_conf_down = (y_pred_proba <= low_conf_threshold).sum()
    
    print(f"\nğŸ“Š é«˜ç½®ä¿¡åº¦é¢„æµ‹:")
    print(f"   é«˜ç½®ä¿¡ä¸Šæ¶¨ (â‰¥{high_conf_threshold}): {high_conf_up} ({high_conf_up/len(y_pred_proba)*100:.1f}%)")
    print(f"   é«˜ç½®ä¿¡ä¸‹è·Œ (â‰¤{low_conf_threshold}): {high_conf_down} ({high_conf_down/len(y_pred_proba)*100:.1f}%)")
    
    if high_conf_up > 0:
        high_conf_up_mask = y_pred_proba >= high_conf_threshold
        high_conf_up_accuracy = accuracy_score(y_test[high_conf_up_mask], y_pred[high_conf_up_mask])
        print(f"   é«˜ç½®ä¿¡ä¸Šæ¶¨å‡†ç¡®ç‡: {high_conf_up_accuracy:.4f} ({high_conf_up_accuracy*100:.2f}%)")
    
    if high_conf_down > 0:
        high_conf_down_mask = y_pred_proba <= low_conf_threshold
        high_conf_down_accuracy = accuracy_score(y_test[high_conf_down_mask], y_pred[high_conf_down_mask])
        print(f"   é«˜ç½®ä¿¡ä¸‹è·Œå‡†ç¡®ç‡: {high_conf_down_accuracy:.4f} ({high_conf_down_accuracy*100:.2f}%)")
    
    # è¯„ä¼°
    print("\n" + "=" * 80)
    print("æ¨¡å‹è¯„ä¼°")
    print("=" * 80)
    
    if auc and auc >= 0.7:
        print("\nâœ… æ¨¡å‹æ€§èƒ½ä¼˜ç§€ï¼")
        print("   â€¢ AUC â‰¥ 0.7ï¼Œå…·æœ‰è‰¯å¥½çš„åŒºåˆ†èƒ½åŠ›")
        print("   â€¢ å¯ä»¥ç”¨äºå®é™…äº¤æ˜“ç­–ç•¥")
    elif auc and auc >= 0.6:
        print("\nâš ï¸  æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œä½†æœ‰æ”¹è¿›ç©ºé—´")
        print("   â€¢ AUC åœ¨ 0.6-0.7 ä¹‹é—´")
        print("   â€¢ å»ºè®®è°¨æ…ä½¿ç”¨ï¼Œå°èµ„é‡‘æµ‹è¯•")
    else:
        print("\nâŒ æ¨¡å‹æ€§èƒ½ä¸è¶³")
        print("   â€¢ AUC < 0.6")
        print("   â€¢ å»ºè®®é‡æ–°è®­ç»ƒæˆ–è°ƒæ•´ç‰¹å¾")
    
    print("\n" + "=" * 80)
    
    return {
        'auc': auc,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'high_conf_up': high_conf_up,
        'high_conf_down': high_conf_down,
    }

if __name__ == "__main__":
    try:
        # åŠ è½½æ¨¡å‹
        print("\nğŸ¤– åŠ è½½æœ€æ–°æ¨¡å‹...")
        model_path = load_latest_model_path()
        if not model_path:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
            sys.exit(1)
        model = joblib.load(model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
        
        # åŠ è½½æ•°æ®
        df_feat = load_test_data()
        if df_feat is None:
            sys.exit(1)
        
        # éªŒè¯æ¨¡å‹
        metrics = validate_model(model, df_feat)
        
        print("\nâœ… éªŒè¯å®Œæˆï¼")
        sys.exit(0)
        
    except Exception as e:
        print(f"\nğŸ’¥ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
