#!/usr/bin/env python3
"""
å¤šå¸ç§æ¨¡å‹è®­ç»ƒè„šæœ¬
ä½¿ç”¨å¤šä¸ªäº¤æ˜“å¯¹çš„æ•°æ®è®­ç»ƒæ¨¡å‹ï¼Œæå‡æ³›åŒ–èƒ½åŠ›
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime, timezone

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from sklearn.metrics import roc_auc_score, classification_report
from butterfly_bot.config.settings import (
    TIMEFRAME,
    TRAIN_TEST_SPLIT_RATIO,
)
from butterfly_bot.data.features import add_features, get_feature_columns
from butterfly_bot.data.fetcher import fetch_ohlcv
from butterfly_bot.model.lgb_model import LGBModel
from butterfly_bot.model.model_registry import save_model_with_metadata, update_latest_model


def main():
    """ä½¿ç”¨å¤šä¸ªå¸ç§è®­ç»ƒæ¨¡å‹"""
    
    # å®šä¹‰å¤šä¸ªäº¤æ˜“å¯¹
    symbols = ["DOGE/USDT", "BTC/USDT", "ETH/USDT"]
    timeframe = TIMEFRAME
    limit = 3000  # æ¯ä¸ªå¸ç§è·å–3000æ ¹Kçº¿
    
    print(f"ğŸ”§ å¼€å§‹å¤šå¸ç§æ¨¡å‹è®­ç»ƒ")
    print(f"äº¤æ˜“å¯¹: {', '.join(symbols)}")
    print(f"å‘¨æœŸ: {timeframe}")
    print(f"æ¯ä¸ªå¸ç§Kçº¿æ•°: {limit}")
    print("=" * 60)
    
    # æ”¶é›†æ‰€æœ‰å¸ç§çš„æ•°æ®
    all_data = []
    
    for symbol in symbols:
        print(f"\nğŸ“¥ è·å– {symbol} æ•°æ®...")
        try:
            df_raw = fetch_ohlcv(symbol=symbol, timeframe=timeframe, limit=limit)
            
            if len(df_raw) < 200:
                print(f"âš ï¸  {symbol} æ•°æ®é‡ä¸è¶³ï¼ˆ{len(df_raw)}æ¡ï¼‰ï¼Œè·³è¿‡")
                continue
            
            print(f"âœ… è·å– {len(df_raw)} æ ¹Kçº¿")
            
            # æ„å»ºç‰¹å¾
            df_feat = add_features(df_raw)
            
            if len(df_feat) == 0:
                print(f"âš ï¸  {symbol} ç‰¹å¾å·¥ç¨‹åæ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡")
                continue
            
            # æ·»åŠ å¸ç§æ ‡è¯†ï¼ˆå¯é€‰ï¼Œç”¨äºåˆ†æï¼‰
            df_feat['symbol'] = symbol
            
            all_data.append(df_feat)
            print(f"âœ… {symbol} æœ‰æ•ˆæ ·æœ¬: {len(df_feat)}")
            
        except Exception as e:
            print(f"âŒ {symbol} æ•°æ®è·å–å¤±è´¥: {e}")
            continue
    
    if len(all_data) == 0:
        raise ValueError("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è®­ç»ƒæ•°æ®")
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    print(f"\nğŸ”„ åˆå¹¶ {len(all_data)} ä¸ªå¸ç§çš„æ•°æ®...")
    df_combined = pd.concat(all_data, ignore_index=True)
    
    # ç§»é™¤symbolåˆ—ï¼ˆä¸ç”¨äºè®­ç»ƒï¼‰
    if 'symbol' in df_combined.columns:
        df_combined = df_combined.drop('symbol', axis=1)
    
    print(f"âœ… åˆå¹¶åæ€»æ ·æœ¬æ•°: {len(df_combined)}")
    
    # æ£€æŸ¥ç›®æ ‡å˜é‡
    if "target" not in df_combined.columns:
        raise ValueError("âŒ ç¼ºå°‘ç›®æ ‡å˜é‡ 'target'")
    
    y = df_combined["target"]
    if y.nunique() < 2:
        raise ValueError("âŒ ç›®æ ‡å˜é‡æ— å˜åŒ–ï¼Œæ— æ³•è®­ç»ƒåˆ†ç±»æ¨¡å‹")
    
    # å‡†å¤‡ç‰¹å¾
    feature_cols = get_feature_columns()
    missing_features = set(feature_cols) - set(df_combined.columns)
    if missing_features:
        raise ValueError(f"âŒ ç¼ºå°‘ç‰¹å¾åˆ—: {missing_features}")
    
    X = df_combined[feature_cols]
    
    print(f"ğŸ§© ç‰¹å¾ç»´åº¦: {len(feature_cols)}")
    print(f"ğŸ“Š æ­£æ ·æœ¬æ¯”ä¾‹: {y.mean():.2%}")
    
    # æ—¶åºåˆ†å‰²ï¼ˆä¿æŒæ—¶é—´é¡ºåºï¼‰
    split_idx = int(len(X) * TRAIN_TEST_SPLIT_RATIO)
    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
    
    if len(X_train) == 0 or len(X_test) == 0:
        raise ValueError("âŒ è®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©º")
    
    print(f"ğŸ“Š è®­ç»ƒé›†: {len(X_train)} | æµ‹è¯•é›†: {len(X_test)}")
    print("=" * 60)
    
    # è®­ç»ƒæ¨¡å‹
    print("\nğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    model = LGBModel()
    model.train(X_train, y_train, X_val=X_test, y_val=y_test)
    
    # è¯„ä¼°æ¨¡å‹
    print("\nğŸ“ˆ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    y_pred_proba = model.predict(X_test)
    y_pred = (y_pred_proba >= 0.5).astype(int)
    
    try:
        auc = float(roc_auc_score(y_test, y_pred_proba))
        print(f"âœ… æµ‹è¯•é›† AUC: {auc:.4f}")
    except ValueError as e:
        print(f"âš ï¸  AUC è®¡ç®—å¤±è´¥: {e}")
        auc = 0.5
    
    # æ‰“å°åˆ†ç±»æŠ¥å‘Š
    print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred, target_names=['ä¸‹è·Œ', 'ä¸Šæ¶¨']))
    
    # ä¿å­˜æ¨¡å‹
    print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
    metadata = {
        "symbols": symbols,
        "timeframe": timeframe,
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "train_size": len(X_train),
        "test_size": len(X_test),
        "auc": auc,
        "feature_count": len(feature_cols),
        "model_type": "multi_symbol",
    }
    
    version = save_model_with_metadata(model, metadata)
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜ä¸ºç‰ˆæœ¬: {version}")
    
    # æ›´æ–°ä¸ºæœ€æ–°æ¨¡å‹
    update_latest_model(version, auc)
    print(f"âœ… å·²æ›´æ–°ä¸ºæœ€æ–°æ¨¡å‹")
    
    print("\n" + "=" * 60)
    print(f"ğŸ‰ å¤šå¸ç§æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print(f"ç‰ˆæœ¬: {version}")
    print(f"AUC: {auc:.4f}")
    print(f"ç‰¹å¾æ•°: {len(feature_cols)}")
    print(f"è®­ç»ƒæ ·æœ¬: {len(X_train)}")
    print("=" * 60)


if __name__ == "__main__":
    main()
